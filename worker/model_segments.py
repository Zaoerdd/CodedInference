import torch
import torch.nn as nn
import torch.nn.functional as F
# from torchvision import models
from models.VGG16 import vgg16
from model_utils import auto_segment_model

# class SegmentEncoder(nn.Module):
#     """
#     å¯¹åº”å›¾ä¸­çš„ Encoder Eï¼Œä½¿ç”¨ CNN å®ç°ã€‚
#     """
#     def __init__(self, k_workers, r_workers, in_channels):
#         super().__init__()
#         self.k = k_workers
#         self.r = r_workers
#         # è®©æˆ‘ä»¬è®¡ç®—å•ä¸ªåˆ†ç‰‡çš„é€šé“æ•° C_k:
#         C_k = in_channels // k_workers
#         # æ‹¼æ¥åçš„é€šé“æ•° C_total åº”è¯¥æ˜¯ C_k * k = in_channelsã€‚
#         # (å‡è®¾ in_channels å¯ä»¥è¢« k_workers æ•´é™¤)
#         self.in_channels = in_channels 
        
#         # self.in_channels = in_channels # <--- ä½¿ç”¨è¿™ä¸ªä¿®å¤

#         self.cnn_body = nn.Sequential(
#             nn.Conv2d(self.in_channels, 64, kernel_size=3, padding=1), nn.ReLU(),
#             nn.Conv2d(64, 32, kernel_size=1), nn.ReLU()
#         )
#         self.parity_heads = nn.ModuleList(
#             [nn.Conv2d(32, C_k, kernel_size=3, padding=1) for _ in range(r_workers)]
#         )
#         # self.in_channels = in_channels * k_workers
#         # self.cnn_body = nn.Sequential(
#         #     nn.Conv2d(self.in_channels, 64, kernel_size=3, padding=1), nn.ReLU(),
#         #     nn.Conv2d(64, 32, kernel_size=1), nn.ReLU()
#         # )
#         # self.parity_heads = nn.ModuleList(
#         #     [nn.Conv2d(32, in_channels, kernel_size=3, padding=1) for _ in range(r_workers)]
#         # )
#     def forward(self, list_of_k_tensors):
#         concatenated_tensor = torch.cat(list_of_k_tensors, dim=1)
#         features = self.cnn_body(concatenated_tensor)
#         parity_pieces = [head(features) for head in self.parity_heads]
#         return parity_pieces

class SegmentEncoder(nn.Module):
    """
    å¯¹åº”å›¾ä¸­çš„ Encoder Eï¼Œä½¿ç”¨ CNN å®ç°ã€‚
    é€‚ç”¨äºç©ºé—´åˆ†ç‰‡ï¼šæ¥æ”¶ k ä¸ªç©ºé—´åˆ†ç‰‡ï¼Œæ²¿é€šé“ç»´åº¦æ‹¼æ¥åè¿›è¡Œç¼–ç ã€‚
    """
    def __init__(self, k_workers, r_workers, in_channels):
        super().__init__()
        self.k = k_workers
        self.r = r_workers
        
        # 1. ç©ºé—´åˆ†ç‰‡ç¼–ç ï¼šSegmentEncoderçš„è¾“å…¥é€šé“æ˜¯ k ä¸ªåˆ†ç‰‡æ²¿é€šé“æ‹¼æ¥åçš„æ€»é€šé“æ•°ã€‚
        # æ¯ä¸ªåˆ†ç‰‡æœ‰ in_channels ä¸ªé€šé“ï¼Œæ‹¼æ¥åä¸º in_channels * k_workersã€‚
        self.in_channels = in_channels * k_workers 
        
        self.cnn_body = nn.Sequential(
            nn.Conv2d(self.in_channels, 64, kernel_size=3, padding=1), nn.ReLU(),
            nn.Conv2d(64, 32, kernel_size=1), nn.ReLU()
        )
        # 2. å¥‡å¶æ ¡éªŒç‰‡çš„é€šé“æ•°æ˜¯åŸå§‹é€šé“æ•° in_channelsã€‚
        self.parity_heads = nn.ModuleList(
            [nn.Conv2d(32, in_channels, kernel_size=3, padding=1) for _ in range(r_workers)]
        )
        
    def forward(self, list_of_k_tensors):
        """
        list_of_k_tensors: k ä¸ªç©ºé—´åˆ†ç‰‡ï¼Œå½¢çŠ¶å‡ä¸º [B, C, H/k, W]
        """
        # 3. æ²¿é€šé“ç»´åº¦ (dim=1) æ‹¼æ¥ k ä¸ªç©ºé—´åˆ†ç‰‡
        # ç»“æœå½¢çŠ¶: [B, C*k, H/k, W]
        concatenated_tensor = torch.cat(list_of_k_tensors, dim=1)
        
        features = self.cnn_body(concatenated_tensor)
        parity_pieces = [head(features) for head in self.parity_heads]
        return parity_pieces

# class SegmentFinalDecoder(nn.Module):
#     """
#     å¯¹åº”å›¾ä¸­çš„ Decoder Dï¼Œä½¿ç”¨ CNN å®ç°ã€‚
#     """
#     def __init__(self, k_workers, out_channels, final_width):
#         super().__init__()
#         self.k = k_workers
#         self.in_channels = out_channels * k_workers
#         self.final_width = final_width
#         self.reconstructor = nn.Sequential(
#             nn.Conv2d(self.in_channels, 128, kernel_size=3, padding=1), nn.ReLU(),
#             nn.Conv2d(128, 64, kernel_size=3, padding=1), nn.ReLU(),
#             nn.Conv2d(64, out_channels, kernel_size=1)
#         )
#     def forward(self, k_outputs, k_indices):
#         sorted_pairs = sorted(zip(k_indices, k_outputs), key=lambda p: p[0])
#         sorted_outputs = [p[1] for p in sorted_pairs]
#         concatenated_tensor = torch.cat(sorted_outputs, dim=1)
#         reconstructed_full = self.reconstructor(concatenated_tensor)
#         reconstructed_full = F.interpolate(reconstructed_full, size=(reconstructed_full.shape[2], self.final_width))
#         return reconstructed_full

class SegmentFinalDecoder(nn.Module):
    """
    å¯¹åº”å›¾ä¸­çš„ Decoder Dï¼Œä½¿ç”¨ CNN å®ç°ã€‚
    ä¿®æ­£ä¸ºï¼šå…¼å®¹ç©ºé—´åˆ†ç‰‡ (æ²¿é«˜åº¦ dim=2 æ‹¼æ¥)ã€‚
    """
    def __init__(self, k_workers, out_channels, final_width):
        super().__init__()
        self.k = k_workers
        # ğŸ› ä¿®æ­£ï¼šin_channels ç°åœ¨åº”è¯¥æ˜¯ out_channelsï¼ˆå› ä¸ºæ²¿é«˜åº¦æ‹¼æ¥ï¼Œé€šé“ä¸å˜ï¼‰
        self.in_channels = out_channels # <--- ä¿®æ­£: æ²¿é«˜åº¦æ‹¼æ¥ï¼Œé€šé“æ•°ä¸å˜
        self.final_width = final_width
        self.reconstructor = nn.Sequential(
            # ğŸ› ä¿®æ­£ï¼šç¡®ä¿å·ç§¯å±‚çš„è¾“å…¥é€šé“æ•°ä¸æ‹¼æ¥åçš„é€šé“æ•°ä¸€è‡´
            nn.Conv2d(out_channels, 128, kernel_size=3, padding=1), nn.ReLU(),
            nn.Conv2d(128, 64, kernel_size=3, padding=1), nn.ReLU(),
            nn.Conv2d(64, out_channels, kernel_size=1)
        )
    def forward(self, k_outputs, k_indices):
        sorted_pairs = sorted(zip(k_indices, k_outputs), key=lambda p: p[0])
        sorted_outputs = [p[1] for p in sorted_pairs]
        
        # 1. ğŸ› ä¿®æ­£ï¼šæ²¿ã€é«˜åº¦ç»´åº¦ã€‘ (dim=2) æ‹¼æ¥ k ä¸ªç©ºé—´åˆ†ç‰‡
        # å³ä½¿åˆ†å—ä¸å‡åŒ€ï¼Œä¹Ÿå¿…é¡»æ²¿é«˜åº¦æ‹¼æ¥
        concatenated_tensor = torch.cat(sorted_outputs, dim=2) # <--- ä¿®æ­£ä¸º dim=2
        
        reconstructed_full = self.reconstructor(concatenated_tensor)
        
        # 2. ğŸ› ä¿®æ­£ï¼šç§»é™¤æˆ–ä¿®æ­£æ’å€¼
        # ç§»é™¤å¯èƒ½å¯¼è‡´é«˜åº¦é”™è¯¯çš„ F.interpolateï¼Œå› ä¸ºç©ºé—´åˆ†ç‰‡è¦æ±‚æ‰€æœ‰å¼ é‡ W ç›¸åŒã€‚
        # å¦‚æœéœ€è¦è°ƒæ•´ Wï¼Œå¯ä»¥æ‰§è¡Œï¼š
        if reconstructed_full.shape[3] != self.final_width:
             print(f"[WARN] Decoder æ­£åœ¨è°ƒæ•´å®½åº¦: {reconstructed_full.shape[3]} -> {self.final_width}")
             reconstructed_full = F.interpolate(reconstructed_full, 
                                                 size=(reconstructed_full.shape[2], self.final_width))
        
        # å¦åˆ™ï¼Œç›´æ¥è¿”å›
        return reconstructed_full

class BlockWorkerDecoder(nn.Module):
    """ 
    é€šç”¨çš„å·ç§¯å— Worker è§£ç å™¨ã€‚
    """
    def __init__(self, layer_configs):
        super().__init__()
        self.conv_layers = nn.ModuleList()
        for in_channels, out_channels in layer_configs:
            self.conv_layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))
    def forward(self, x):
        for conv_layer in self.conv_layers:
            x = F.relu(conv_layer(x))
        return x

# --- ä¸»è¦ä¿®æ”¹: åŠ¨æ€æ¨¡å‹åŠ è½½å™¨ ---
def load_segment_models_dynamically(model_name, k_workers, r_workers, input_shape):
    """
    åŠ¨æ€åœ°åŠ è½½ã€åˆ†å‰²ä»»ä½•å…¼å®¹çš„æ¨¡å‹ï¼Œå¹¶ä¸ºæ¯ä¸ªæ®µåˆ›å»ºæ‰€éœ€çš„ç»„ä»¶ã€‚
    """
    master_models = {}
    worker_models = {}

    # 1. æ ¹æ®åç§°åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
    if model_name.lower() == 'vgg16':
        model = vgg16()
    # elif model_name.lower() == 'alexnet':
    #     model = models.alexnet()
    else:
        raise ValueError(f"æ¨¡å‹ '{model_name}' å°šä¸æ”¯æŒè‡ªåŠ¨åˆ†å‰²ã€‚")
    
    # 2. è°ƒç”¨æˆ‘ä»¬çš„æ–°å·¥å…·æ¥è‡ªåŠ¨åˆ†å‰²æ¨¡å‹
    block_configs, pooling_layers = auto_segment_model(model, input_shape)
    print(f"æ¨¡å‹ '{model_name}' è¢«è‡ªåŠ¨åˆ†å‰²ä¸º {len(block_configs)} ä¸ªå—ã€‚")
    
    if not block_configs:
        raise RuntimeError("æ¨¡å‹åˆ†å‰²å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹ç»“æ„ã€‚")

    # 3. æ ¹æ®åŠ¨æ€ç”Ÿæˆçš„é…ç½®æ¥æ„å»ºæ‰€æœ‰ç»„ä»¶
    for block_name, configs in block_configs.items():
        encoder = SegmentEncoder(k_workers, r_workers, configs['in_c'])
        final_decoder = SegmentFinalDecoder(k_workers, configs['out_c'], configs['width'])
        worker_decoder = BlockWorkerDecoder(configs['layers'])
        
        master_models[block_name] = (encoder, final_decoder)
        worker_models[block_name] = worker_decoder

    # å°†æ‰€æœ‰æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    for key in master_models:
        master_models[key][0].eval()
        master_models[key][1].eval()
        worker_models[key].eval()
    
    # Master èŠ‚ç‚¹éœ€è¦çŸ¥é“åœ¨æ®µä¹‹é—´åº”ç”¨å“ªäº›æ± åŒ–å±‚
    return master_models, worker_models, pooling_layers
