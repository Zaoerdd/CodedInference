{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca91a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "from new_model.model_segments import load_segment_models_nlcc\n",
    "\n",
    "def test_pipeline_local(n_workers, k_workers):\n",
    "    \"\"\"\n",
    "    测试本地的 NLCC 完整流程\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Testing with N={n_workers}, K={k_workers} ---\")\n",
    "\n",
    "    # 1. 加载模型\n",
    "    # 确保 load_segment_models_nlcc 接受 n 和 k\n",
    "    try:\n",
    "        master_models, worker_models = load_segment_models_nlcc(n_workers, k_workers)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading models: {e}\")\n",
    "        print(\"确保 'load_segment_models_nlcc' 接受 (n, k) 参数\")\n",
    "        return\n",
    "\n",
    "    # 假设只有一个 segment 'seg1'\n",
    "    encoder, coder, final_decoder = master_models['seg1']\n",
    "    worker_decoder = worker_models['seg1']\n",
    "\n",
    "    # 2. 创建一个虚拟输入\n",
    "    # (batch_size, channels, H, W)\n",
    "    x = torch.randn((1, 3, 224, 224))\n",
    "    print(f\"Input shape: {x.shape}\")\n",
    "\n",
    "    # 3. 模拟 Master 端的 Encoder 和 Coder\n",
    "    with torch.no_grad():\n",
    "        z = encoder(x)\n",
    "        print(f\"Latent shape (z): {z.shape}\")\n",
    "        \n",
    "        # zs_coded 是一个包含 N 个张量的列表\n",
    "        zs_coded = coder(z) \n",
    "        print(f\"Coded latent pieces: {len(zs_coded)}, Shape of one: {zs_coded[0].shape}\")\n",
    "\n",
    "    # 4. 模拟 K 个 Worker 的工作\n",
    "    # 我们从 N 个编码块中只选择 K 个\n",
    "    # 关键：选择任意 K 个，例如前 K 个\n",
    "    k_indices_to_use = list(range(k_workers))\n",
    "    k_coded_outputs = []\n",
    "\n",
    "    print(f\"Simulating {k_workers} workers (indices: {k_indices_to_use})...\")\n",
    "    with torch.no_grad():\n",
    "        for i in k_indices_to_use:\n",
    "            z_coded_i = zs_coded[i]\n",
    "            # 模拟 Worker i 的解码\n",
    "            y_coded_i = worker_decoder(z_coded_i)\n",
    "            k_coded_outputs.append(y_coded_i)\n",
    "            \n",
    "    print(f\"Worker intermediate outputs: {len(k_coded_outputs)}, Shape of one: {k_coded_outputs[0].shape}\")\n",
    "\n",
    "    # 5. 模拟 Master 端的 FinalDecoder\n",
    "    with torch.no_grad():\n",
    "        start_time = time.time()\n",
    "        # FinalDecoder 必须能够从这 K 个块和它们的索引中重建\n",
    "        y_pred = final_decoder(k_coded_outputs, k_indices_to_use)\n",
    "        duration = time.time() - start_time\n",
    "\n",
    "    print(f\"Final output shape (y_pred): {y_pred.shape}\")\n",
    "    print(f\"FinalDecoder duration: {duration:.4f}s\")\n",
    "    \n",
    "    # 检查最终形状是否符合预期\n",
    "    # (例如，您在 model_segments_nlcc.py 中定义的 final_output_shape)\n",
    "    expected_shape = (1, 64, 112, 112) \n",
    "    assert y_pred.shape == expected_shape\n",
    "    print(f\"Test N={n_workers}, K={k_workers} PASSED!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27a43518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing with N=2, K=2 ---\n",
      "Input shape: torch.Size([1, 3, 224, 224])\n",
      "Latent shape (z): torch.Size([1, 16, 56, 56])\n",
      "Coded latent pieces: 2, Shape of one: torch.Size([1, 512])\n",
      "Simulating 2 workers (indices: [0, 1])...\n",
      "Worker intermediate outputs: 2, Shape of one: torch.Size([1, 64, 28, 28])\n",
      "Final output shape (y_pred): torch.Size([1, 64, 112, 112])\n",
      "FinalDecoder duration: 4.2502s\n",
      "Test N=2, K=2 PASSED!\n",
      "\n",
      "--- Testing with N=3, K=2 ---\n",
      "Input shape: torch.Size([1, 3, 224, 224])\n",
      "Latent shape (z): torch.Size([1, 16, 56, 56])\n",
      "Coded latent pieces: 3, Shape of one: torch.Size([1, 512])\n",
      "Simulating 2 workers (indices: [0, 1])...\n",
      "Worker intermediate outputs: 2, Shape of one: torch.Size([1, 64, 28, 28])\n",
      "Final output shape (y_pred): torch.Size([1, 64, 112, 112])\n",
      "FinalDecoder duration: 7.1004s\n",
      "Test N=3, K=2 PASSED!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 运行测试 ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 测试 1: \"uncoded\" / \"repetition\" 场景 (k=n)\n",
    "    # n=2, k=2\n",
    "    test_pipeline_local(n_workers=2, k_workers=2)\n",
    "\n",
    "    # 测试 2: *真正的 NLCC 容错场景* (k < n)\n",
    "    # n=3, k=2\n",
    "    test_pipeline_local(n_workers=3, k_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a64819af",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _imaging: 操作系统无法运行 %1。",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# 确保 model_utils 和 model_segments 可以在 Python 路径中被找到\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 假设这些文件与本测试脚本在同一目录下\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\OneDrive\\Study\\CodedInference-main\\.pixi\\envs\\default\\Lib\\site-packages\\torchvision\\__init__.py:10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Don't re-order these, we need to load the _C extension (done when importing\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# .extensions) before entering _meta_registrations.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\OneDrive\\Study\\CodedInference-main\\.pixi\\envs\\default\\Lib\\site-packages\\torchvision\\datasets\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_optical_flow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FlyingChairs, FlyingThings3D, HD1K, KittiFlow, Sintel\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_stereo_matching\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      3\u001b[39m     CarlaStereo,\n\u001b[32m      4\u001b[39m     CREStereo,\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     SintelStereo,\n\u001b[32m     13\u001b[39m )\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcaltech\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Caltech101, Caltech256\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\OneDrive\\Study\\CodedInference-main\\.pixi\\envs\\default\\Lib\\site-packages\\torchvision\\datasets\\_optical_flow.py:10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decode_png, read_file\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfolder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m default_loader\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\OneDrive\\Study\\CodedInference-main\\.pixi\\envs\\default\\Lib\\site-packages\\PIL\\Image.py:90\u001b[39m\n\u001b[32m     81\u001b[39m MAX_IMAGE_PIXELS: \u001b[38;5;28mint\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28mint\u001b[39m(\u001b[32m1024\u001b[39m * \u001b[32m1024\u001b[39m * \u001b[32m1024\u001b[39m // \u001b[32m4\u001b[39m // \u001b[32m3\u001b[39m)\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the _imaging C module is not present, Pillow will not load.\u001b[39;00m\n\u001b[32m     86\u001b[39m     \u001b[38;5;66;03m# Note that other modules should not refer to _imaging directly;\u001b[39;00m\n\u001b[32m     87\u001b[39m     \u001b[38;5;66;03m# import Image and use the Image.core variable instead.\u001b[39;00m\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# Also note that Image.core is not a publicly documented interface,\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# and should be considered private and subject to change.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _imaging \u001b[38;5;28;01mas\u001b[39;00m core\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m __version__ != \u001b[38;5;28mgetattr\u001b[39m(core, \u001b[33m\"\u001b[39m\u001b[33mPILLOW_VERSION\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     93\u001b[39m         msg = (\n\u001b[32m     94\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe _imaging extension was built for another version of Pillow or PIL:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCore version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mgetattr\u001b[39m(core,\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mPILLOW_VERSION\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     96\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPillow version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     97\u001b[39m         )\n",
      "\u001b[31mImportError\u001b[39m: DLL load failed while importing _imaging: 操作系统无法运行 %1。"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "import sys\n",
    "\n",
    "# 确保 model_utils 和 model_segments 可以在 Python 路径中被找到\n",
    "# 假设这些文件与本测试脚本在同一目录下\n",
    "try:\n",
    "    from model_utils import auto_segment_model\n",
    "    from model_segments import load_segment_models_dynamically\n",
    "except ImportError:\n",
    "    print(\"错误: 请确保 'model_utils.py' 和 'model_segments.py' 文件与此测试脚本在同一目录下。\")\n",
    "    sys.exit(1)\n",
    "\n",
    "def run_test_for_model(model_name, input_shape, k, r):\n",
    "    \"\"\"\n",
    "    对指定的模型运行一套完整的分割和加载测试。\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*20} 开始测试: {model_name.upper()} {'='*20}\")\n",
    "    \n",
    "    try:\n",
    "        # --- 步骤 1: 调用动态加载器 ---\n",
    "        # 这一步同时测试了 model_utils.py 和 model_segments.py\n",
    "        print(f\"--> 正在调用 load_segment_models_dynamically for '{model_name}'...\")\n",
    "        master_models, worker_models, pooling_layers = load_segment_models_dynamically(\n",
    "            model_name=model_name,\n",
    "            k_workers=k,\n",
    "            r_workers=r,\n",
    "            input_shape=input_shape\n",
    "        )\n",
    "        print(\"--> 动态加载成功！\")\n",
    "\n",
    "        # --- 步骤 2: 验证输出的正确性 ---\n",
    "        num_blocks = len(master_models)\n",
    "        print(f\"\\n--- 验证结果 ---\")\n",
    "        print(f\"识别出的卷积块数量: {num_blocks}\")\n",
    "        print(f\"识别出的池化层数量: {len(pooling_layers)}\")\n",
    "        \n",
    "        # 断言检查\n",
    "        assert num_blocks > 0, f\"测试失败: 未能为 '{model_name}' 识别出任何卷积块。\"\n",
    "        assert len(master_models) == len(worker_models), \"测试失败: Master 和 Worker 的模型数量不匹配。\"\n",
    "        # 通常，池化层的数量比卷积块少一个\n",
    "        assert abs(len(master_models) - len(pooling_layers)) <= 1, \"测试失败: 池化层和卷积块的数量关系不正确。\"\n",
    "\n",
    "        print(\"\\n--- 详细配置检查 ---\")\n",
    "        for i, block_name in enumerate(master_models.keys()):\n",
    "            print(f\"  - 块 {i+1}: '{block_name}'\")\n",
    "            assert block_name in worker_models, f\"测试失败: Worker 模型中缺少 '{block_name}'。\"\n",
    "            \n",
    "            encoder, final_decoder = master_models[block_name]\n",
    "            worker_decoder = worker_models[block_name]\n",
    "            \n",
    "            # 检查模型类型是否正确\n",
    "            assert isinstance(encoder, torch.nn.Module), f\"测试失败: '{block_name}' 的 Encoder 不是一个 nn.Module。\"\n",
    "            assert isinstance(final_decoder, torch.nn.Module), f\"测试失败: '{block_name}' 的 FinalDecoder 不是一个 nn.Module。\"\n",
    "            assert isinstance(worker_decoder, torch.nn.Module), f\"测试失败: '{block_name}' 的 WorkerDecoder 不是一个 nn.Module。\"\n",
    "            print(f\"    - Encoder, FinalDecoder, WorkerDecoder 实例已成功创建。\")\n",
    "\n",
    "        print(f\"\\n{'='*20} 测试成功: {model_name.upper()} {'='*20}\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n{'!'*20} 测试失败: {model_name.upper()} {'!'*20}\")\n",
    "        print(f\"错误信息: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 定义测试参数\n",
    "    k = 4  # 系统化任务数\n",
    "    r = 2  # 校验任务数\n",
    "    \n",
    "    # --- 测试 VGG16 ---\n",
    "    vgg_input_shape = (1, 3, 224, 224)\n",
    "    vgg_success = run_test_for_model('vgg16', vgg_input_shape, k, r)\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "    \n",
    "    # --- 测试 AlexNet ---\n",
    "    alexnet_input_shape = (1, 3, 224, 224) # AlexNet 也使用 224x224\n",
    "    alexnet_success = run_test_for_model('alexnet', alexnet_input_shape, k, r)\n",
    "\n",
    "    print(\"\\n\" + \"#\"*50)\n",
    "    if vgg_success and alexnet_success:\n",
    "        print(\"所有测试均已通过！自动化分割和动态加载功能工作正常。\")\n",
    "    else:\n",
    "        print(\"部分或全部测试失败。请检查上面的错误日志。\")\n",
    "    print(\"#\"*50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
